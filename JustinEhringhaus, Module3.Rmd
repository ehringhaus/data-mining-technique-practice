---
title: "Module 3 Technique Practice"
author: "Justin Ehringhaus"
date: "____, 2022"
output:
  github_document: default
bibliography: "references.bib"
nocite: '@*'
---

- Decision Tree
- Random Forest
- K-Means clustering
- Hierarchical clustering
- Association Rule (apriori algorithm)
- GAM (refer to "Case study on grain yields" from datacamp)

Can make conclusions whether it worked or didn't work. Can use LDA below and describe WHY it didn't work. Results don't matter as much as trying / explaining.

Group members should use different approaches, but same dataset.

Could use K-means clustering to 1) find homogeneous subgroups within larger group and 2) find patterns in the features of the data (i.e., dimensionality reduction) OR 3) pre-processing before supervised learning.

```{r setup, include=FALSE}
# repo: https://github.com/ehringhaus/data-mining-technique-practice.git 
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(pacman)
p_load(tidyverse)  # usual suite of packages
```

# Data

```{r}
wvs <- read_csv("/Users/justin/Desktop/ALY 6040/Project/Repo/WVS_Cross-National_Wave_7_csv_v4_0.csv")

wvs_subset <- 
  wvs %>% 
  select(
    # --------------------------- DEMOGRAPHICS
    Country = B_COUNTRY_ALPHA,
    Longitude = O1_LONGITUDE,
    Latitude = O2_LATITUDE,
    Settlement.type = H_SETTLEMENT,
    Country.and.year = S025,
    Town.size = G_TOWNSIZE2,
    Age = Q262,
    Income.Group = Q288,
    Ethnic.Group = Q290, # see WVS_codebook.pdf for Q290 coding info
    Immigrant = Q263,
    Religion = Q289,
    Marital.Status = Q273,
    Education = Q275,
    Number.Children = Q274,
    Happiness = Q46,
    Health = Q47,
    # --------------------------- POLITICAL PARTICIPATION / CONFIDENCE IN GOVERNMENT
    votes.locally = Q221,
    votes.nationally = Q222,
    confidence.elections = Q76,
    confidence.courts = Q70,
    confidence.UN = Q83,
    environment.vs.econgrow = Q111,
    # --------------------------- RELATIONSHIP BETWEEN GOVERNMENT AND CITIZENS
    cheating.taxes = Q180,
    gov.video.surveillance = Q196,
    gov.email.monitoring = Q197,
    gov.collecting.info = Q198,
    # --------------------------- ETHICAL VALUES ---------------------------
    terrorism = Q192,
    death.penalty = Q195,
    suicide = Q187,
    beating.wife = Q189,
    beating.children = Q190,
    # --------------------------- SOCIAL VIEWS ---------------------------
    homosexuality = Q182,
    prostitution = Q183,
    abortion = Q184,
    divorce = Q185,
    casual.sex = Q193,
    sex.before.marriage = Q186,
    # --------------------------- CAREER VALUES ---------------------------
    importance.leisure.time = Q3,
    importance.work = Q5,
    # --------------------------- IMMIGRATION ---------------------------
    job.scarc.prioritizes.nonimm = Q34,
    imm.fills.useful.jobs = Q122,
    imm.strengthens.cultural.div = Q123,
    imm.increases.crime.rate = Q124,
    imm.gives.political.asylum = Q125,
    imm.increases.terrorism.risk = Q126,
    imm.helps.poor = Q127,
    imm.increases.unemployment = Q128,
    imm.brings.social.conflict = Q129,
    imm.policy.preference = Q130
    )
```


# OPTION 1: Decision Tree

```{r}
# packages needed
p_load(rpart)
p_load(caret)
p_load(rpart.plot)
p_load(rattle)
#data splicing
set.seed(12345)
train <- sample(1:nrow(mushrooms), size = ceiling(0.80 * nrow(mushrooms)), replace = FALSE)
# training set
mushrooms_train <- mushrooms[train,]
# test set
mushrooms_test <- mushrooms[-train,]
# penalty matrix
penalty.matrix <- matrix(c(0, 1, 10, 0), byrow = TRUE, nrow = 2)
# building the classification tree with rpart
tree <- rpart(formula = class ~ .,
              data = mushrooms_train,
              parms = list(loss = penalty.matrix),
              method = "class")
# Details of the decision tree
summary(tree)
# Visualize the decision tree with rpart.plot
rpart.plot(tree, nn = TRUE)
# choosing the best complexity parameter "cp" to prune the tree
cp.optim <- tree$cptable[which.min(tree$cptable[,"xerror"]), "CP"]
# tree prunning using the best complexity parameter
tree <- prune(tree, cp = cp.optim)
# Details of the pruned decision tree
summary(tree)
#Testing the model
pred <- predict(object = tree, mushrooms_test[-1], type = "class")
#Calculating accuracy
t <- table(mushrooms_test$class, pred)
confusionMatrix(t)
ctable <- as.table(confusionMatrix(t))
fourfoldplot(ctable, 
             color = c("brown1", "chartreuse1"), 
             conf.level = 0, 
             margin = 1, 
             main = "Confusion Matrix")
```

# OPTION 2: Classification

```{r}

```


# OPTION 3: Clustering

```{r}
# Common Algorithms: Hierarchical / K-Means
```

# OPTION 4: Association Mining

```{r}

```

# OPTION 5: Linear Discriminant Analysis (LDA)

```{r}
# source: https://www.r-bloggers.com/2021/05/linear-discriminant-analysis-in-r/
p_load(klaR)
p_load(psych)
p_load(MASS)
p_load(BiocManager)
p_load(ggord)
p_load(devtools)

wvs_lda <- wvs_subset[c("Happiness", 
                        "Income.Group", 
                        "Marital.Status",
                        "Number.Children",
                        "Country",
                        "Town.size")]

# create a scatterplot for the first four numerical variables.
pairs.panels(wvs_lda[2:6],
             gap = 0,
             bg = c("red", "green", "blue", "orange")[wvs_subset$Happiness],
             pch = 21)
# create a training dataset and test dataset for prediction and testing purposes. 
set.seed(123)
ind <- sample(2, nrow(wvs_lda),
              replace = TRUE,
              prob = c(0.6, 0.4))
training <- wvs_subset[c(15, 27:31)][ind==1,]
testing <- wvs_subset[c(15, 27:31)][ind==2,]
# Linear discriminant analysis
linear <- lda(Happiness~., training)
linear
# Stacked histogram for discriminant function values. These histograms are based on ld1. It’s clearly evident that no overlaps between first and second and first and third species. But some overlap observed between the second and third species.
p <- predict(linear, training)
ldahist(data = p$x[,1], g = training$Happiness)
# histogram based on lda2 showing complete overlap and its not good.
ldahist(data = p$x[,2], g = training$Happiness)
# Biplot based on LD1  and LD2. Setosa separated very clearly and some overlap observed between Versicolor and virginica. Based on arrows, Sepal width and sepal length explained more for setosa, petal width and petal length explained more for versicolor and virginica.
ggord(linear, training$Happiness, ylim = c(-10, 10))
# Partition plot. It provides the classification of each and every combination in the training dataset.
partimat(Happiness~., data = training, method = "lda")
partimat(Happiness~., data = training, method = "qda")
# Confusion matrix and accuracy – training data
p1 <- predict(linear, training)$class
tab <- table(Predicted = p1, Actual = training$Happiness)
tab
# In the training dataset total correct classification is 33+26+25=84. The accuracy of the model is around 0.9767442
sum(diag(tab))/sum(tab)
# Confusion matrix and accuracy – testing data. The accuracy of the model is around .984375
p2 <- predict(linear, testing)$class
tab1 <- table(Predicted = p2, Actual = testing$Happiness)
tab1
sum(diag(tab1))/sum(tab1)
```

